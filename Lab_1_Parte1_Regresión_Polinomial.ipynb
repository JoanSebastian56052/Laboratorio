{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab_1_Parte1_Regresión_Polinomial.ipynb","version":"0.3.2","provenance":[],"toc_visible":true},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"JWwary3Pkxak","colab_type":"text"},"source":["# Laboratorio 1 - Parte 1\n","\n","### Regresión polinomial múltiple\n","\n","### 2019 - I\n","\n","#### Profesor: Julián D. Arias Londoño\n","#### julian.ariasl@udea.edu.co\n"]},{"cell_type":"markdown","metadata":{"id":"BZvKQ9bBkxar","colab_type":"text"},"source":["## Guía del laboratorio\n","\n","En este archivo va a encontrar tanto celdas de código como celdas de texto con las instrucciones para desarrollar el laboratorio.\n","\n","Lea atentamente las instrucciones entregadas en las celdas de texto correspondientes y proceda con la solución de las preguntas planteadas.\n","\n","Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."]},{"cell_type":"code","metadata":{"id":"ljf2gdp9kxa0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bk5lBkS6kxbP","colab_type":"text"},"source":["#### Primer integrante:\n","\n","Nombre: Joan Sebastian Morales Ocampo\n","Cedula: 1047971484\n","\n","#### Segundo integrante:\n","\n","Nombre: Sebastian Londoño Alvarez\n","Cedula: 1152445286\n"]},{"cell_type":"code","metadata":{"id":"8MgVIuagkxbU","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import stats\n","\n","#Algunas advertencias que queremos evitar\n","import warnings\n","warnings.filterwarnings(\"always\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eyGvG-eBkxb0","colab_type":"text"},"source":["## Ejercicio 1: Contextualización del problema (1/1)\n","\n","El problema de *regresión* que abordaremos consiste en predecir el valor de la humedad absoluta en el aire, a partir de varias variables sensadas en el aire (Para más información sobre la base de datos y la contextualización del problema, consulte: http://archive.ics.uci.edu/ml/datasets/air+quality). Ejecute la siguiente celda para cargar los datos."]},{"cell_type":"code","metadata":{"id":"kXC-uaXWkxcf","colab_type":"code","colab":{}},"source":["#cargamos la bd que está en un archivo .data y ahora la podemos manejar de forma matricial\n","db = np.loadtxt('DB/AirQuality.data',delimiter='\\t')  # Assuming tab-delimiter\n","\n","#Esta es la base de datos AirQuality del UCI Machine Learning Repository.\n","X = db[:,0:12]\n","Y = db[:,12]\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KBhUtX9ikxdG","colab_type":"text"},"source":["#### Responda:\n","\n","1.1 Cuántas muestras tiene la base de datos?: \n","\n","\n"]},{"cell_type":"code","metadata":{"id":"tlLf2GwHkxdK","colab_type":"code","colab":{},"outputId":"8176b0f5-10a7-4b68-85be-34434ea59d9b"},"source":["N = np.size(X,0)\n","print (N)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["9357\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZH5q5Jy3kxdt","colab_type":"text"},"source":["1.2 Cuántas caracteristicas tiene el problema?: \n","\n"]},{"cell_type":"code","metadata":{"id":"DTnvotbmkxdy","colab_type":"code","colab":{},"outputId":"c76aeecb-8117-488f-ebe6-2ff41732b968"},"source":["d = np.size(X,1)\n","print (d)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["12\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r6jYiDE0k_3k","colab_type":"text"},"source":["**Escriban algo**"]},{"cell_type":"markdown","metadata":{"id":"LcUiy4jckxeJ","colab_type":"text"},"source":["<b>Nota</b>: Agregue una celda en la cual incluya las líneas de código usadas para responder las preguntas."]},{"cell_type":"markdown","metadata":{"id":"FQM49kc5kxeP","colab_type":"text"},"source":["## Ejercicio 2: Completar código (0.8/1)\n","\n","Analice los siguientes métodos de la teoría vista para los modelos de *regresión polinomial múltiple*, tales como el error cuadrático medio (<font color='blue'>ECM</font>), modelo de regresión múltiple (<font color='blue'>regression</font>), potencia del polinomio (<font color='blue'>potenciaPolinomio</font>) y gradiente descendente. \n","\n","Una vez comprenda su funcionamiento proceda a realizar lo siguiente: \n","1. Completar el código de la regla de actualización de los parámetros del algoritmo de <font color='blue'>gradiente_descedente</font>: \n","\n","$$w_j(iter) = w_j(iter-1) - \\eta \\frac{\\partial E(w)}{\\partial w_j}$$ \n","\n","2. Graficar el error cuadrático: Error cuadrático medio (ECM) vs. las iteraciones del algoritmo. La gráfica debe llevar título y los correspondientes nombres de los ejes, puedes consultar documentación [aquí](https://matplotlib.org/tutorials/introductory/pyplot.html)."]},{"cell_type":"code","metadata":{"id":"QVbjN0CfkxeU","colab_type":"code","colab":{}},"source":["from __future__ import division\n","\n","#Error cuadrático medio (criterio para el modelo de regresión polinomial)\n","def ECM(Y_est,Y):\n","    N = np.size(Y)\n","    ecm = np.sum((Y_est.reshape(N,1) - Y.reshape(N,1))**2)/(2*N)\n","    return ecm \n","\n","#Modelo Regresión Múltiple\n","def regression(X, W):\n","    Yest = np.dot(X,W)    #con np.dot se realiza el producto matricial. Aquí X es dim [Nxd] y W es dim [dx1]\n","    return Yest           #Esta variable contiene la salida de f(X,W)\n","\n","\n","#Potencia de polinomio\n","def potenciaPolinomio(X,grado):\n","    X2 = X\n","    \n","    if grado != 1:\n","        for i in range(2,grado+1):\n","            Xadd = X**i\n","            X2 = np.concatenate((X2, Xadd), axis=1)\n","    \n","    return X2\n","\n","\n","\"\"\"Gradiente descendente para regresión lineal múltiple\n","X: Matriz de datos extendida.\n","W: Vector de parámetros del modelo\n","eta: Taza de aprendizaje\n","\"\"\"\n","   \n","def gradiente_descendente(X,Y,eta):\n","     \n","    #Extendemos la matriz de X para el parámetro independiente\n","    unos = np.array([np.ones(np.size(X,0))])\n","    #Concatenamos el vector de unos con la matriz X\n","    X = np.concatenate((unos.T, X), axis=1)\n","    X = X.reshape(np.size(X,0),np.size(X,1))\n","    \n","    Y = Y.reshape(np.size(Y), 1)\n","    \n","    #Tomamos el número de variables del problema\n","    d = np.size(X,1)\n","    \n","    #Tomamos el número de muestras de la base de datos\n","    N = np.size(X,0)\n","    \n","    \n","    #Inicializamos el vector de parámetros \n","    W = np.zeros((1,d))\n","    W = W.reshape(np.size(W), 1)\n","    \n","    eta = eta\n","    \n","    iteraciones = 500\n","    ecms = np.zeros(iteraciones)\n","    \n","    for iter in range(iteraciones):\n","        error = ECM(regression(X,W),Y)\n","        ecms[iter] = error\n","        \n","        #Aquí debe completar el código con la regla de actualización de los parámetros W. \n","        #Tenga en cuenta los nombres de las variables ya creadas: W, X, Y\n","        for j in range(d):\n","            suma = 0\n","            for i in range(N):\n","                suma += (np.dot(W.T, X[i, :].T) - Y[i]) * X[i, j]\n","            W[j] = W[j] - eta * suma / N\n","        # Se calcula el error cuadrático medio con base  a X, Y, W actualizado\n","        error = ECM(regression(X, W), Y)\n","        ecms[iter] = error\n","        \n","        \n","    print ('Vector de parámetros del modelo:\\n')\n","    print (W)\n","    print ('\\nError Final durante el entrenamiento = ' + str(ecms[-1]))\n","    \n","    #Aquí debe completar el código para realizar la gráfica de ecms vs. iteraciones\n","    iteraciones = np.linspace(1, 500, 500)\n","    plt.title('ecms vs iteraciones')\n","    plt.xlabel('iteraciones')\n","    plt.ylabel('ecms')\n","    plt.plot(iteraciones, ecms, color='green')\n","    plt.show()\n","    \n","    return W\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-gxkzZ6AlL7p","colab_type":"text"},"source":["**Dónde comprueban que el código funciona?**"]},{"cell_type":"markdown","metadata":{"id":"uuPlE2wakxek","colab_type":"text"},"source":["## Ejercicio 3: Entrenamiento (1/1)\n","\n","En este punto debe hacer uso de las funciones escritas en el punto anterior para realizar el proceso de *modelamiento y simulación* de los datos de cargados en el Ejercicio # 1 sobre la predicción del valor de la humedad absoluta en el aire \n","\n","A continuación complete el siguiente código llamando a la función <font color='blue'>gradiente_descedente</font> pasandole los parámetros correspondientes (X,y,eta). Debe obtener como salida el vector de parámetros $w$ estimado y la gráfica del error cuadrático medio vs iteraciones.\n","\n","*Nota*: No olvide definir el grado del polinomio y la taza de aprendizaje (eta)"]},{"cell_type":"code","metadata":{"id":"eI7Knpbekxeq","colab_type":"code","colab":{},"outputId":"9eca1827-4183-4b43-f31f-0631989d9777"},"source":["from numpy import random\n","import math\n","import numpy.matlib\n","\n","\n","N = np.size(X,0)\n","\n","# #Se modifica la matriz de datos original de acuerdo al grado del polinomio ingresado para el modelo\n","grado = 2\n","X2 = potenciaPolinomio(X,grado)\n","\n","#Dejamos algunas muestras para el proceso de entrenamiento y otras para evaluar qué tan bueno fue el aprendizaje del modelo\n","random.seed(1)\n","ind=np.random.permutation(N)\n","Xtrain = X2[ind[0:int(math.ceil(0.7*N))],:]\n","Xtest = X2[ind[int(math.ceil(0.7*N)):N],:]\n","Ytrain = Y[ind[0:int(math.ceil(0.7*N))]]\n","Ytest = Y[ind[int(math.ceil(0.7*N)):N]]\n","\n","#Normalizamos los datos\n","media = np.mean(Xtrain)\n","desvia = np.std(Xtrain)\n","Xtrain = stats.stats.zscore(Xtrain)\n","Xtest = (Xtest - np.matlib.repmat(media, Xtest.shape[0], 1))/np.matlib.repmat(desvia, Xtest.shape[0], 1)\n","\n","eta = 1e-1\n","\n","#Complete la siguiente línea de código llamando el método gradiente_descendente con sus respectivos argumentos\n","W = gradiente_descendente(Xtrain, Ytrain, eta)\n","\n","#Evaluamos las predicciones del modelo con los datos de test\n","unos = np.array([np.ones(np.size(Xtest,0))])\n","Xtest = np.concatenate((unos.T, Xtest), axis=1)\n","Xtest = Xtest.reshape(np.size(Xtest,0),np.size(Xtest,1))\n","Yest = regression(Xtest, W)\n","Error = ECM(Yest,Ytest)\n","print ('\\nError durante la prueba = ' + str(Error))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Vector de parámetros del modelo:\n","\n","[[-7.13434276]\n"," [-0.07400147]\n"," [ 2.87692169]\n"," [-0.22481694]\n"," [ 7.72851919]\n"," [ 0.94943972]\n"," [-0.4057207 ]\n"," [ 2.81805872]\n"," [ 0.26105871]\n"," [ 0.32017528]\n"," [ 0.34154942]\n"," [ 6.17625873]\n"," [ 5.93978829]\n"," [-0.07569192]\n"," [-1.58676459]\n"," [ 0.18906272]\n"," [-6.12465562]\n"," [-1.00626941]\n"," [ 0.24208009]\n"," [-1.3980778 ]\n"," [-0.03271551]\n"," [-1.08586742]\n"," [-0.25412185]\n"," [-5.84185628]\n"," [-5.4160829 ]]\n","\n","Error Final durante el entrenamiento = 0.11036575402759395\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["\n","Error durante la prueba = 845.3198976188897\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"27d815OmoBtq","colab_type":"text"},"source":["***Ésta no es la función usada en el laboratorio del viernes**"]},{"cell_type":"markdown","metadata":{"id":"PKmwYdy7kxfB","colab_type":"text"},"source":["#### Responda:\n","\n","3.1 ¿Cuál es el número de coeficientes $w$ que se obtienen al ingresar un polinomio de grado 4? ¿Por qué?:\n","* El número de coeficientes de W que se obtiene para un polinómio de grado 4 es 49, lo cual corresponde a doce coeficientes por cada vector X y un coeficiente para el término independiente $$ f(x,{\\bf{w}} ) = w_0 + w_1 X +  w_2 X^2 + w_3 X^3 + w_4 X^4$$ \n","\n"]},{"cell_type":"code","metadata":{"id":"cNax2w_qkxfG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrAqkhxZkxfW","colab_type":"text"},"source":["3.2 La funci&oacute;n polin&oacute;mica que se est&aacute; usando para grados mayores a 1\n","est&aacute; incompleta, ¿Por qu&eacute;?:\n","* La función resultante que no incluye los términos son los terminos cruzados $x_1x_2^2$ ..."]},{"cell_type":"markdown","metadata":{"id":"4MbLPVg7kxfc","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"F00G0zcvkxfg","colab_type":"text"},"source":["## Ejercicio 4: Obtener resultados (0/1)\n","\n","Identifique la variable \"eta\" (tasa de aprendizaje $\\eta$) en el código anterior, cambie su valor de acuerdo a la siguiente tabla. Haga lo mismo con el valor del grado del polinomio y complete las columnas ECM_Entrenamiento y ECM_Prueba.\n","\n","Tenga en cuenta que cuando el valor de $\\eta$ sea $0.00001$ y el grado del polinomio sea $1$, el valor del ECM de prueba debe ser $703.376$. Esto le servirá de criterio de verificación para la implementación de su algorítmo de gradiente descendente.\n"]},{"cell_type":"code","metadata":{"id":"yGysH3O5kxfk","colab_type":"code","colab":{},"outputId":"faf03ab4-03bd-418e-ef4c-3694c513fc72"},"source":["import numpy as np\n","import pandas as pd\n","import qgrid\n","randn = np.random.randn\n","df_types = pd.DataFrame({\n","    'Tasa de aprendizaje' : pd.Series(['1e-5', '1e-5', '1e-5', '1e-5', '1e-5', '1e-3', '1e-3', '1e-3', '1e-3', '1e-3', '1e-1', '1e-1', '1e-1', '1e-1', '1e-1']),\n","    'Grado del polinomio' : pd.Series([1,2,3,4,5,1,2,3,4,5,1,2,3,4,5])})\n","df_types[\"ECM_Entrenamiento\"] = \"\"\n","df_types[\"ECM_Prueba\"] = \"\"\n","df_types.set_index(['Tasa de aprendizaje','Grado del polinomio'], inplace=True)\n","df_types[\"ECM_Entrenamiento\"][0] = \"774.055\"\n","df_types[\"ECM_Prueba\"][0] = \"703.376\"\n","#df_types.sort_index(inplace=True)\n","qgrid_widget = qgrid.show_grid(df_types, show_toolbar=False)\n","qgrid_widget"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4873513f3bb74b67ad6c0ee3bf26740e","version_major":2,"version_minor":0},"text/plain":["QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"d4XADP6Xkxf5","colab_type":"text"},"source":["Ejecute la siguiente instrucción para dejar guardados en el notebook los resultados de las pruebas."]},{"cell_type":"code","metadata":{"id":"yrlJxMySkxf-","colab_type":"code","colab":{},"outputId":"403cdbe5-351c-41d0-e145-dcb63eb6a4fa"},"source":["qgrid_widget.get_changed_df()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th></th>\n","      <th>ECM_Entrenamiento</th>\n","      <th>ECM_Prueba</th>\n","    </tr>\n","    <tr>\n","      <th>Tasa de aprendizaje</th>\n","      <th>Grado del polinomio</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">1e-5</th>\n","      <th>1</th>\n","      <td>774.055</td>\n","      <td>703.376</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>748.0650199329715</td>\n","      <td>709.8818828072049</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>724.8281620841035</td>\n","      <td>709.8473166611931</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>703.2141392035185</td>\n","      <td>711.3701531480207</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>682.618236994124</td>\n","      <td>711.4026416401626</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">1e-3</th>\n","      <th>1</th>\n","      <td>47.29527684830529</td>\n","      <td>432.36244848825163</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>19.369835798422308</td>\n","      <td>666.8547928838403</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13.51182461520417</td>\n","      <td>715.0872818014203</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11.329200038805741</td>\n","      <td>716.5566416177581</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>10.468907336782845</td>\n","      <td>711.3664458640579</td>\n","    </tr>\n","    <tr>\n","      <th rowspan=\"5\" valign=\"top\">1e-1</th>\n","      <th>1</th>\n","      <td>0.9227684951432751</td>\n","      <td>1337.7484636331963</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.1103657540275942</td>\n","      <td>845.3198976188901</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.04780332693437483</td>\n","      <td>685.3369170531051</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.024716351580914724</td>\n","      <td>674.3636159960561</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.02813775021868516</td>\n","      <td>679.1952705182399</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            ECM_Entrenamiento  \\\n","Tasa de aprendizaje Grado del polinomio                         \n","1e-5                1                                 774.055   \n","                    2                       748.0650199329715   \n","                    3                       724.8281620841035   \n","                    4                       703.2141392035185   \n","                    5                        682.618236994124   \n","1e-3                1                       47.29527684830529   \n","                    2                      19.369835798422308   \n","                    3                       13.51182461520417   \n","                    4                      11.329200038805741   \n","                    5                      10.468907336782845   \n","1e-1                1                      0.9227684951432751   \n","                    2                      0.1103657540275942   \n","                    3                     0.04780332693437483   \n","                    4                    0.024716351580914724   \n","                    5                     0.02813775021868516   \n","\n","                                                 ECM_Prueba  \n","Tasa de aprendizaje Grado del polinomio                      \n","1e-5                1                               703.376  \n","                    2                     709.8818828072049  \n","                    3                     709.8473166611931  \n","                    4                     711.3701531480207  \n","                    5                     711.4026416401626  \n","1e-3                1                    432.36244848825163  \n","                    2                     666.8547928838403  \n","                    3                     715.0872818014203  \n","                    4                     716.5566416177581  \n","                    5                     711.3664458640579  \n","1e-1                1                    1337.7484636331963  \n","                    2                     845.3198976188901  \n","                    3                     685.3369170531051  \n","                    4                     674.3636159960561  \n","                    5                     679.1952705182399  "]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"1JhmyTQjkxgT","colab_type":"text"},"source":["## Ejercicio 5: Pruebas (0.2/1)\n","\n","En la celda de código del Ejercicio # 3, comente la línea donde se normalizan las matrices de datos Xtrain y Xtest. Realice pruebas para diferentes valores de $\\eta$ y de grado del polinomio de manera similar a los valores que usó en el punto 3. Observe que pasa con el ECM.\n","\n","#### Responda\n","\n","4.1 Qué sucede con los valores del ECM?\n","* Los valores de ECM se convierten en nan. \n","\n"]},{"cell_type":"code","metadata":{"id":"68f-LqhqkxgX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rmlUtx57kxgs","colab_type":"text"},"source":["4.2 A qué se debe lo que observa?\n","* El problema anterior se debe al error \"overflow encountered in square\" lo cual nos indica que es un valor que se sale del rango permitido para un tipo de dato float64.\n"]},{"cell_type":"code","metadata":{"id":"o38sbIrGkxgx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mZEHVzeFkxhB","colab_type":"text"},"source":["4.3 ¿Qu&eacute; proceso hace la normalizaci&oacute;n sobre los datos? Consulte por qu&eacute; es necesaria la normalizaci&oacute;n en el modelo de regresi&oacute;n log&iacute;stica y cu&aacute;les son los tipos de normalizaci&oacute;n m&aacute;s comunes. ¿Cu&aacute;l de ellos se aplic&oacute; en el laboratorio?\n","* EL proceso de normalización comprime o extiende los valores de los datos de entrada a un rango de valores definido, para el caso en particular los comprime.\n"," * La normalización de los datos es necesaria para reducir la redundancia y ajustar el conjuntos de datos.  Los principales métodos para la normalización de datos son:\n"," * * Normalización Min Max\n"," * * Normalización Z-score\n"," * * Normalizado por escala decimal\n"," * Para el caso en particular se ha empleado la ténica de normalización Standard score o Z-score, la cual se muestra a continuación:\n","  $$ X_{normalized} = \\frac{X - X_{mean}}{X_{stddev}} $$"]},{"cell_type":"code","metadata":{"id":"aE9dZ-D-kxhH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qlgxg5Gfoxbz","colab_type":"text"},"source":["**¿Dónde esá el código que soporte la respuesta?**"]},{"cell_type":"markdown","metadata":{"id":"EOQdcH0jpfn1","colab_type":"text"},"source":["**Éste no es el taller del laboratorio de los viernes**"]},{"cell_type":"code","metadata":{"id":"s5XV1LyEo1GA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}